{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script><script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window._Plotly) {require(['plotly'],function(plotly) {window._Plotly=plotly;});}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script><script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window._Plotly) {require(['plotly'],function(plotly) {window._Plotly=plotly;});}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# this package needs to be loaded to open a file dialogue to open the data file\n",
    "#from tkinter import filedialog\n",
    "#from tkinter import *\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import curve_fit\n",
    "import math\n",
    "import os.path\n",
    "import os\n",
    "import sys\n",
    "import plotly.offline as py\n",
    "from scipy.interpolate import interp1d\n",
    "import scipy.fftpack as ft\n",
    "py.init_notebook_mode(connected=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the data file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def data_import (filename, N_headers):\n",
    "    data = []\n",
    "    \n",
    "    f = open(filename, 'r')\n",
    "    for i in np.arange(N_headers):\n",
    "        f.readline()\n",
    "    \n",
    "    for line in f:\n",
    "        line=line.strip()\n",
    "        line=line.split()\n",
    "        \n",
    "        for i in np.arange(len(line)):\n",
    "            line[i] = float(line[i])\n",
    "        \n",
    "        data.append(line)\n",
    "    \n",
    "    data = np.array(data)\n",
    "        \n",
    "    final_data = []\n",
    "    for i in np.arange(len(line)):\n",
    "        final_data.append(data[:,i])\n",
    "    \n",
    "    return np.array(final_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the final data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def save (data, names, units, comments, filename):\n",
    "    Units = ''\n",
    "    Comments = ''\n",
    "    Names = ''\n",
    "    \n",
    "    for i in np.arange(len(data)-1):\n",
    "        Units = Units + units[i] + '\\t'\n",
    "        Comments = Comments + comments[i] + '\\t'\n",
    "        Names = Names + names[i] + '\\t'\n",
    "           \n",
    "    Units = Units + units[len(data)-1] + '\\n'\n",
    "    Comments = Comments + comments[len(data)-1] + '\\n'\n",
    "    Names = Names + names[len(data)-1] + '\\n'\n",
    "    \n",
    "       \n",
    "    if os.path.isfile(filename) == True:\n",
    "        x='w'\n",
    "    else:\n",
    "        x='x'\n",
    "        \n",
    "    with open(filename, x) as g:\n",
    "        g.write(Names)\n",
    "        g.write(Units)\n",
    "        g.write(Comments)\n",
    "        for i in np.arange(len(data[0])):\n",
    "            Data = ''\n",
    "            \n",
    "            for j in np.arange(len(data)-1):\n",
    "                Data = Data + str(data[j][i]) + '\\t'\n",
    "            \n",
    "            Data = Data + str(data[-1][i]) + '\\n'\n",
    "            \n",
    "            g.write(Data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## from the filename a string with the information about frequency and temperature is extracted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def comment ( filename ) :\n",
    "        \n",
    "    namefile = filename[::-1]\n",
    "    position = namefile.find('\\\\')\n",
    "    file = filename[-position:]\n",
    "    \n",
    "    \n",
    "    # temperature sweep\n",
    "    if file[0] == '-':\n",
    "        namefile = filename[::-1]\n",
    "        position = namefile.find('\\\\')\n",
    "        file = filename[-position:]\n",
    "        \n",
    "        fb = file.find('F')\n",
    "        fe = file.find('G')\n",
    "        Tb = file.find('T')\n",
    "        Te = file.find('K')\n",
    "        \n",
    "        comment = file[Tb+1:Te]+'K '+file[fb+1:fe]+'GHz'\n",
    "        \n",
    "    \n",
    "    # individual measurement\n",
    "    else:\n",
    "        F = file.find('F')\n",
    "        p = file.find('p')\n",
    "        T = file.find('T')\n",
    "        K = file.find('K')\n",
    "        \n",
    "        if file[F+1] == '0':\n",
    "            frequency = file[F+2:p]+'.'+file[p+1:T]+'GHz'\n",
    "        \n",
    "        else:\n",
    "            frequency = file[F+1:p]+'.'+file[p+1:T]+'GHz'\n",
    "            \n",
    "        if file[T+1] == '0':\n",
    "            Temp = file[T+2:K+1]\n",
    "        else:\n",
    "            Temp = file[T+1:K+1]\n",
    "            \n",
    "        comment = Temp+' '+frequency\n",
    "    \n",
    "    return (comment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Switch two data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def swap (data1, data2):\n",
    "    return [data2, data1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot amplitude and phase\n",
    "this function shows a plot of the amplitude and phase against the magnetic field in the same diagram;\n",
    "amlitude and phase share the x-axis but have different y-axes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def plot (Amp, Phase, Field):\n",
    "    fig, ax1 = plt.subplots()\n",
    "    \n",
    "    ax1.set_xlabel('field')\n",
    "    ax1.set_ylabel('amp', color = 'red')\n",
    "    ax1.plot(Field, Amp, color = 'red')\n",
    "    ax1.tick_params(axis='y', labelcolor = 'red')\n",
    "    \n",
    "    ax2 = ax1.twinx()\n",
    "    \n",
    "    ax2.set_ylabel('phase', color = 'navy')\n",
    "    ax2.plot(Field, Phase, color = 'navy')\n",
    "    ax2.tick_params(axis='y', labelcolor = 'navy')\n",
    "    \n",
    "    fig.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove jumps from a data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def jumps (data, Field, dev):\n",
    "    # I am taking the first (dphase) and second (ddphase) derivative of the phase to see jumps more clearly\n",
    "    # I will later use that continuous signals usually flatten with higher derivatives whereas jumps don'taking\n",
    "    # another reason for using the second and not the first derivative is that at a jump the second derivative will\n",
    "    # show two peaks (one positive and one negative) whereas there will be only one at the first derivative\n",
    "    # this gives us another criteria to distinguish between jumps and just big but continuous derivatives\n",
    "    \n",
    "    # note that I am not really taking a derivative since I am not deviding by deltaB, but assuming that the field steps\n",
    "    # are equidistant that will only result in an overall factor\n",
    "    \n",
    "    # first derivative\n",
    "    # note that I am taking the derivative only from one side;\n",
    "    # taking it from both would give me two positive peaks already in the first derivative\n",
    "    # so for simplicity I am only taking a one-sided derivative\n",
    "    ddata = []\n",
    "    for i in np.arange(len(data)):\n",
    "        if i < len(data)-1:\n",
    "            ddata.append(data[i+1]-data[i])\n",
    "        else:\n",
    "            ddata.append(data[i]-data[i-1])\n",
    "    \n",
    "    ddata = np.array(ddata)\n",
    "    \n",
    "    # second derivative\n",
    "    dddata = []\n",
    "    for i in np.arange(len(data)):\n",
    "        if i < len(data)-1:\n",
    "            dddata.append(ddata[i+1]-ddata[i])\n",
    "        else:\n",
    "            dddata.append(ddata[i]-ddata[i-1])\n",
    "    \n",
    "    dddata = np.array(dddata)\n",
    "    \n",
    "    \n",
    "    # in this step I am calculating the mean and standard deviation of the second derivative\n",
    "    ave = np.mean(abs(dddata))\n",
    "    std = np.std(abs(dddata))\n",
    "    \n",
    "    \n",
    "    # here I am finding the jumps (i.e their indices in the respective arrays)\n",
    "    # jumps are features that are \"deviation\" times the standard deviation away from the mean of the second derivative\n",
    "    deviation = dev\n",
    "    \n",
    "    \n",
    "    # note that jumps also need to have two features right next to each other\n",
    "    # remember: 0th derivative: jump\n",
    "    #  1st derivative: 1 peak\n",
    "    #  2nd derivative: 2 peaks right next to each other with opposite sign\n",
    "    \n",
    "    # for now this condition is fulfilled (because deviation=3)\n",
    "    # I am using this while loop to being able to repeat the following step several times if I am not happy with the outcome\n",
    "    # what I can change in between the different tries is \"deviation\"\n",
    "    while deviation != '':\n",
    "        \n",
    "        # index gives you an array with the indices of suspected jumps\n",
    "        # if there is no jump suspected this array will be empty\n",
    "        # in order to distinguish the case of no jump and several jumps the condition len(index)>0 will be posed \n",
    "        # several times in the following\n",
    "        index = np.arange(len(data))[abs(dddata)>ave+float(deviation)*std]\n",
    "        \n",
    "        # this is the case of several jumps\n",
    "        if len(index) > 0:\n",
    "            # I am checking if there are pairs of jumps right next to each other\n",
    "            mask = [False]\n",
    "            for i in (np.arange(len(index)-1)+1):\n",
    "                if index[i-1] == index[i]-1:\n",
    "                    mask.append(True)\n",
    "                else:\n",
    "                    mask.append(False)\n",
    "                    \n",
    "            \n",
    "            # index finally gives you the indices of the jumps\t\n",
    "            index1 = index[mask]\n",
    "            \n",
    "            # now I am plotting the phase and dots on top of it where jumps are suspected\n",
    "            # jumpsx and y give the phase and field of the jump\n",
    "            # note that the jump occurs from the index given in index1 to the following data point\n",
    "            # for plotting a dot where the jump is expected using the average values is most convenient\n",
    "            jumpsx = [(Field[i]+Field[i+1])/2 for i in index1]\n",
    "            jumpsy = [(data[i]+data[i+1])/2 for i in index1]\n",
    "            \n",
    "            \n",
    "            plt.plot(Field, data, zorder = 0)\n",
    "            plt.scatter(jumpsx, jumpsy, color='r', zorder=1, s=8)\n",
    "            plt.show()\n",
    "            print ('Number of jumps = '+str(len(jumpsx)))\n",
    "            \n",
    "            \n",
    "            # now based on the plot above I am asking you whether the dots actually mark jumps\n",
    "            # your answer options are:\n",
    "            # - consecutive letters of 'n' and 'y' (e.g. nnyyyyny) for each dot from left to right; those will be the jumps that are removed in the following\n",
    "            # - enter a number; this number will be a new value for \"deviation\" and we will repeat the search for jumps with this different value \n",
    "            # - enter 'end': this will interrupt the python code - note that you can do this at any point you are asked for input\n",
    "            # - hit enter and you will continue with the amplitude\n",
    "            jumps = input('which of the marked points are actually jumps (enter y/n for jump/no jump)? Or do you maybe want to change the number of standard deviations the jump has to be away from the mean (enter a number)? ' )\n",
    "            if jumps == '':\n",
    "                deviation = ''\n",
    "                index = []\n",
    "            elif jumps[0] == 'n' or jumps[0] == 'y':\n",
    "                deviation = ''\n",
    "            elif jumps == 'end':\n",
    "                sys.exit()\n",
    "            else:\n",
    "                deviation = float(jumps)\n",
    "                \n",
    "        # this is the case of no jump; you have two options here:\n",
    "        # - hit enter to continue with the same process for the amplitude\n",
    "        # - enter a number; this number will replace the old value for \"deviation\" and the process of finding jumps will be repeated\n",
    "        else:\n",
    "            deviation = input('No jump was found. Do you want to continue with the amplitude (press Enter) or change the numbers of standard deviations the jump has to be away from the mean (enter a number)? ')\n",
    "            if deviation == 'end':\n",
    "                sys.exit()\n",
    "                \n",
    "                \n",
    "    # if there was no jump found and you chose to continue with the amplitude then len(index) will still be zero \n",
    "    # so the code inside the if-loop will not be executed\n",
    "    # otherwise it will be >0\n",
    "    \n",
    "    if len(index)>0:\n",
    "        \n",
    "        # from the string jumps that says 'y'/'n' if there is/isn't a jump a mask (manual_mask) is created\n",
    "        manualmask = []\n",
    "        for i in jumps:\n",
    "            if i == 'n':\n",
    "                manualmask.append(False)\n",
    "            elif i == 'y':\n",
    "                manualmask.append(True)\n",
    "                \n",
    "        # index2 now really gives the indeces of the jumps\n",
    "        index2 = np.array(index1)[manualmask]\n",
    "        \n",
    "        # this is where the jumps in the phase are actually eliminated\n",
    "        data_new = data\n",
    "        # only if there are any jumps left and you didn't tell it that all the suspected points are in fact not jumps\n",
    "        if len(index2)>0:\n",
    "            # for all the jumps\n",
    "            for i in index2:\n",
    "                # I am creating an array that is 0 before and 1 after the jump is happening\n",
    "                a = np.zeros(len(data))\n",
    "                for k in np.arange(len(data)):\n",
    "                    if k > i:\n",
    "                        a[k] = 1\n",
    "                # with this array I can just add the jump to all the values after it\n",
    "                data_new = data_new + (data[i]-data[i+1])*a\n",
    "    else:\n",
    "        data_new = data\n",
    "    \n",
    "    plt.plot(Field, data_new)\n",
    "    \n",
    "    \n",
    "    return data_new\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This defines a polynomial 9th order and a routine that fits an n-th order polynomial (max 9th) to a data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# this defines a 9th order polynomial\n",
    "def polynomial(x, a, b, c, d, e, f, g, h, i, j):\n",
    "    return (a*x**9 + b*x**8 + c*x**7 + d*x**6 + e*x**5 + f*x**4 + g*x**3 + h*x**2 + i*x + j)\n",
    "\n",
    "# this function fits an n-th order polynomial to the amplitude data\n",
    "# input variable of the function are:\n",
    "# - n: the order of the polynomial you want to fit to the data\n",
    "# - xmin: an array of the minimum field values of the signals you want to take out of the fit\n",
    "# - xmax: ... maximum ...\n",
    "# - the amplitude\n",
    "# - the field\n",
    "def fitpolynomial(n, xmin, xmax, amp, field):\n",
    "    mask = np.array([[any([(field<xmin[j])[i],(field>xmax[j])[i]]) for i in np.arange(len(field))] for j in np.arange(len(xmax))])\n",
    "    mask = [all([mask[j,i] for j in np.arange(len(xmax))]) for i in np.arange(len(field))]\n",
    "    fieldcut = field[mask]\n",
    "    ampcut = amp[mask]\n",
    "\n",
    "    if n == 9:\n",
    "        def fct(x, a, b, c, d, e, f, g, h, i, j):\n",
    "            return polynomial(x, a, b, c, d, e, f, g, h, i, j)\n",
    "        parameters, pcov = curve_fit(fct, fieldcut, ampcut)\n",
    "        fit = fct(field, parameters[0], parameters[1], parameters[2], parameters[3], parameters[4], parameters[5], parameters[6], parameters[7], parameters[8], parameters[9])\n",
    "           \n",
    "    elif n==8:\n",
    "        def fct(x, b, c, d, e, f, g, h, i, j):\n",
    "            return polynomial(x, 0, b, c, d, e, f, g, h, i, j)\n",
    "        parameters, pcov = curve_fit(fct, fieldcut, ampcut)\n",
    "        fit = fct(field, parameters[0], parameters[1], parameters[2], parameters[3], parameters[4], parameters[5], parameters[6], parameters[7], parameters[8])\n",
    "           \n",
    "    elif n==7:\n",
    "        def fct(x, c, d, e, f, g, h, i, j):\n",
    "            return polynomial(x, 0, 0, c, d, e, f, g, h, i, j)\n",
    "        parameters, pcov = curve_fit(fct, fieldcut, ampcut)\n",
    "        fit = fct(field, parameters[0], parameters[1], parameters[2], parameters[3], parameters[4], parameters[5], parameters[6], parameters[7])\n",
    "         \n",
    "    elif n==6:\n",
    "        def fct(x, d, e, f, g, h, i, j):\n",
    "            return polynomial(x, 0, 0, 0, d, e, f, g, h, i, j)\n",
    "        parameters, pcov = curve_fit(fct, fieldcut, ampcut)\n",
    "        fit = fct(field, parameters[0], parameters[1], parameters[2], parameters[3], parameters[4], parameters[5], parameters[6])\n",
    "               \n",
    "    elif n==5:\n",
    "        def fct(x, e, f, g, h, i, j):\n",
    "            return polynomial(x, 0, 0, 0, 0, e, f, g, h, i, j)\n",
    "        parameters, pcov = curve_fit(fct, fieldcut, ampcut)\n",
    "        fit = fct(field, parameters[0], parameters[1], parameters[2], parameters[3], parameters[4], parameters[5])\n",
    "               \n",
    "    elif n==4:\n",
    "        def fct(x, f, g, h, i, j):\n",
    "            return polynomial(x, 0, 0, 0, 0, 0, f, g, h, i, j)\n",
    "        parameters, pcov = curve_fit(fct, fieldcut, ampcut)\n",
    "        fit = fct(field, parameters[0], parameters[1], parameters[2], parameters[3], parameters[4])\n",
    "              \n",
    "    elif n==3:\n",
    "        def fct(x, g, h, i, j):\n",
    "            return polynomial(x, 0, 0, 0, 0, 0, 0, g, h, i, j)\n",
    "        parameters, pcov = curve_fit(fct, fieldcut, ampcut)\n",
    "        fit = fct(field, parameters[0], parameters[1], parameters[2], parameters[3])\n",
    "        \n",
    "    elif n==2:\n",
    "        def fct(x, h, i, j):\n",
    "            return polynomial(x, 0, 0, 0, 0, 0, 0, 0, h, i, j)\n",
    "        parameters, pcov = curve_fit(fct, fieldcut, ampcut)\n",
    "        fit = fct(field, parameters[0], parameters[1], parameters[2])\n",
    "                        \n",
    "    elif n==1:\n",
    "        def fct(x, i, j):\n",
    "            return polynomial(x, 0, 0, 0, 0, 0, 0, 0, 0, i, j)\n",
    "        parameters, pcov = curve_fit(fct, fieldcut, ampcut)\n",
    "        fit = fct(field, parameters[0], parameters[1])\n",
    "            \n",
    "    ampsubtract = amp - fit\n",
    "    return (ampsubtract, fit)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subtract a baseline from data\n",
    "### the previous two functions are used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def baseline (data, Field):\n",
    "    \n",
    "    plt.plot(Field, data)\n",
    "    plt.show()\n",
    "    \n",
    "    pos = input('enter the minimum and maximum values of the peaks separated by commas (i.e. min1,max1,min2,max2,...): ')\n",
    "    \n",
    "    allpos = []\n",
    "    for i in np.arange(pos.count(',')):\n",
    "        a = pos.find(',')\n",
    "        allpos.append(float(pos[:a]))\n",
    "        pos = pos[a+1:]\n",
    "    \n",
    "    allpos.append(float(pos))\n",
    "    \n",
    "    xmin = allpos[::2]\n",
    "    xmax = allpos[1::2]\n",
    "    \n",
    "    happy = 'n'\n",
    "    \n",
    "    while happy=='n':\n",
    "        \n",
    "        n = float(input('what order polynomial do you want to fit to the data? '))\n",
    "        ampsubtract = fitpolynomial(n, xmin, xmax, data, field)[0]\n",
    "        fitpoly = fitpolynomial(n, xmin, xmax, data, field)[1]\n",
    "        \n",
    "        fig = plt.figure(figsize=[10,3])\n",
    "        ax1 = fig.add_subplot(1,2,1)\n",
    "        ax2 = fig.add_subplot(1,2,2)\n",
    "        \n",
    "        ax1.plot(field, data)\n",
    "        ax1.plot(field, fitpoly)\n",
    "        \n",
    "        ax2.plot(field, ampsubtract)\n",
    "        \n",
    "        plt.show()\n",
    "        \n",
    "        happy = input('are you happy with the subtracted curve? [y/n/end/new]: ')\n",
    "        \n",
    "        if happy == 'end':\n",
    "            break\n",
    "        \n",
    "        if happy == 'new':\n",
    "            #fig, ax1 = plt.subplots()\n",
    "            \n",
    "            #ax1.set_xlabel('field')\n",
    "            #ax1.set_ylabel('amp', color = 'red')\n",
    "            #ax1.plot(field, amp, color = 'red')\n",
    "            #ax1.tick_params(axis='y', labelcolor = 'red')\n",
    "            \n",
    "            #ax2 = ax1.twinx()\n",
    "            \n",
    "            #ax2.set_ylabel('phase', color = 'navy')\n",
    "            #ax2.plot(field, phase, color = 'navy')\n",
    "            #ax2.tick_params(axis='y', labelcolor = 'navy')\n",
    "            \n",
    "            #fig.tight_layout()\n",
    "            \n",
    "            plt.plot(Field, data)\n",
    "            plt.show()\n",
    "            \n",
    "            \n",
    "            pos = input('enter the minimum and maximum values of the peaks separated by commas (i.e. min1,max1,min2,max2,...): ')\n",
    "            allpos = []\n",
    "            for i in np.arange(pos.count(',')):\n",
    "                a = pos.find(',')\n",
    "                allpos.append(float(pos[:a]))\n",
    "                pos = pos[a+1:]\n",
    "            \n",
    "            allpos.append(float(pos))\n",
    "            \n",
    "            xmin = allpos[::2]\n",
    "            xmax = allpos[1::2]\n",
    "            \n",
    "            happy = 'n'\n",
    "    \n",
    "    return ampsubtract\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize a data set to 1\n",
    "That means that max(data)-min(data) = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def normalize (data):\n",
    "    a = []\n",
    "    for i in np.arange(len(data)):\n",
    "        if np.isnan(data[i]) == True:\n",
    "            a.append(False)\n",
    "        else:\n",
    "            a.append(True)\n",
    "    b = data[a]\n",
    "    return data / np.absolute(max(b) - min(b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kramers Kronig Relation\n",
    "calculates the real part of a susceptibility from a given imaginary part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def Kramers_Kronig (amp, field):\n",
    "    amplitude = lambda x: interp1d(field, amp)(x)\n",
    "    kkr = ft.hilbert(amplitude(field))\n",
    "    \n",
    "    return kkr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase corrections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def phasecorr (Amp, Phase, Field, emin, emax, deltae):\n",
    "    \n",
    "    #Amp = Amp / np.absolute(max(Amp) - min(Amp))\n",
    "    #Phase = Phase / np.absolute(max(Phase) - min(Phase))\n",
    "    \n",
    "    \n",
    "    \n",
    "    data = [ dict(\n",
    "        visible = False,\n",
    "        name = str(epsilon),\n",
    "        x = Field, \n",
    "        y = Amp + epsilon*Phase ) for epsilon in np.arange(emin,emax,deltae) ]\n",
    "    data[0]['visible'] = True\n",
    "    \n",
    "    steps = []\n",
    "    for i in range(len(data)):\n",
    "        step = dict(\n",
    "            method = 'restyle', \n",
    "            label = str(np.arange(emin,emax,deltae)[i]),\n",
    "            args = ['visible', [False] * len(data) ],\n",
    "            )\n",
    "        step['args'][1][i] = True # Toggle i'th trace to \"visible\"\n",
    "        steps.append(step)\n",
    "    \n",
    "    sliders = [ dict(\n",
    "        active = 10,\n",
    "        currentvalue = {\"prefix\": \"epsilon: \"},\n",
    "        pad = {\"t\": 100},\n",
    "        steps = steps)]\n",
    "    \n",
    "    layout = dict( sliders = sliders )\n",
    "    \n",
    "    fig = dict( data = data, layout = layout )\n",
    "    \n",
    "    py.iplot( fig)\n",
    "    \n",
    "    eps = input('enter the value of epsilon you ended up with: ')\n",
    "    \n",
    "    amp_p = (Amp+float(eps)*Phase) / np.sqrt(1+float(eps)**2)\n",
    "    \n",
    "    phase_kkr = Kramers_Kronig (amp_p, Field)\n",
    "    \n",
    "    plot(amp_p, phase_kkr, Field)\n",
    "    \n",
    "    return amp_p, phase_kkr, float(eps)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For ESR data Fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Lorentzian absorption lines - needed for HF-ESR data\n",
    "def one_Lorentzian (x, x0, A, gamma):\n",
    "    return -A * gamma / ( (x-x0)**2 + gamma**2 )\n",
    "\n",
    "def one_Lorentzian_off (x, x0, A, gamma, c):\n",
    "    return (-A * gamma / ( (x-x0)**2 + gamma**2 )) + c\n",
    "\n",
    "def two_Lorentzians_off (x, x01, A1, gamma1, x02, A2, gamma2, c):\n",
    "    return -( A1 * gamma1 / ( (x-x01)**2 + gamma1**2 ) + A2 * gamma2 / ( (x-x02)**2 + gamma2**2 ) ) + c\n",
    "\n",
    "def three_Lorentzians_off (x, x01, A1, gamma1, x02, A2, gamma2, x03, A3, gamma3, c):\n",
    "    signal1 = -A1 * gamma1 / ( (x-x01)**2 + gamma1**2 )\n",
    "    signal2 = -A2 * gamma2 / ( (x-x02)**2 + gamma2**2 )\n",
    "    signal3 = -A3 * gamma3 / ( (x-x03)**2 + gamma3**2 )\n",
    "    return signal1 + signal2 + signal3 + c\n",
    "    \n",
    "\n",
    "# derivatives of Loentzian absorption lines (including the fit of a background line) - needed for fits of X-ESR data\n",
    "def one_Lor (x, x0, A, gamma):\n",
    "    return -2 * A * gamma * (x-x0) / ( (x-x0)**2 + gamma**2 )**2\n",
    "\n",
    "def one_Lor_w_lin_b (x, x0, A, gamma, d, e):\n",
    "    return one_Lor(x, x0, A, gamma) + d*x + e\n",
    "\n",
    "def one_Lor_w_quadr_b (x, x0, A, gamma, c, d, e):\n",
    "    return one_Lor(x, x0, A, gamma) + c*x**2 + d*x + e\n",
    "\n",
    "def two_Lor (x, x01, A1, gamma1, x02, A2, gamma2):\n",
    "    return one_Lor(x, x01, A1, gamma1) + one_Lor(x, x02, A2, gamma2)\n",
    "\n",
    "def two_Lor_w_lin_b (x, x01, A1, gamma1, x02, A2, gamma2, d, e):\n",
    "    return one_Lor(x, x01, A1, gamma1) + one_Lor(x, x02, A2, gamma2) + d*x + e\n",
    "\n",
    "def two_Lor_w_quadr_b (x, x01, A1, gamma1, x02, A2, gamma2, c, d, e):\n",
    "    return one_Lor(x, x01, A1, gamma1) + one_Lor(x, x02, A2, gamma2) + c*x**2 + d*x + e\n",
    "\n",
    "def three_Lor_w_lin_b (x, x01, A1, gamma1, x02, A2, gamma2, x03, A3, gamma3, d, e):\n",
    "    return one_Lor(x, x01, A1, gamma1) + one_Lor(x, x02, A2, gamma2) + one_Lor(x, x03, A3, gamma3)+ d*x + e\n",
    "\n",
    "def three_Lor_w_quadr_b (x, x01, A1, gamma1, x02, A2, gamma2, x03, A3, gamma3, c, d, e):\n",
    "    return one_Lor(x, x01, A1, gamma1) + one_Lor(x, x02, A2, gamma2) + one_Lor(x, x03, A3, gamma3)+ c*x**2 + d*x + e\n",
    "\n",
    "# px and py have to be defined somewhere before using the function\n",
    "# they are not supposed to be fit parameters\n",
    "def two_Lor_w_constrained1_quadr_b (x, x01, A1, gamma1, x02, A2, gamma2, c, d):\n",
    "    return one_Lor(x, x01, A1, gamma1) + one_Lor(x, x02, A2, gamma2) + c*x**2 + d*x + (py - c*px**2 - d*px)\n",
    "\n",
    "def two_Lor_w_constrained2_quadr_b (x, x01, A1, gamma1, x02, A2, gamma2, c, e):\n",
    "    return one_Lor(x, x01, A1, gamma1) + one_Lor(x, x02, A2, gamma2) + c*x**2 + ( (py-e)/px -c*px )*x + e\n",
    "\n",
    "def two_Lor_w_constrained3_quadr_b (x, x01, A1, gamma1, x02, A2, gamma2, d, e):\n",
    "    return one_Lor(x, x01, A1, gamma1) + one_Lor(x, x02, A2, gamma2) + (py-e-d*px)/px/px*x**2 + d*x + e\n",
    "\n",
    "def three_Lor_w_constrained1_quadr_b (x, x01, A1, gamma1, x02, A2, gamma2, x03, A3, gamma3, c, d):\n",
    "    a = one_Lor(x, x01, A1, gamma1) + one_Lor(x, x02, A2, gamma2) + one_Lor(x, x03, A3, gamma3)+ c*x**2 + d*x + (py - c*px**2 - d*px)\n",
    "    return a\n",
    "\n",
    "def three_Lor_w_constrained2_quadr_b (x, x01, A1, gamma1, x02, A2, gamma2, x03, A3, gamma3, c, e):\n",
    "    a = one_Lor(x, x01, A1, gamma1) + one_Lor(x, x02, A2, gamma2) + one_Lor(x, x03, A3, gamma3)+ c*x**2 + ( (py-e)/px -c*px )*x + e\n",
    "    return a\n",
    "\n",
    "def three_Lor_w_constrained3_quadr_b (x, x01, A1, gamma1, x02, A2, gamma2, x03, A3, gamma3, d, e):\n",
    "    a = one_Lor(x, x01, A1, gamma1) + one_Lor(x, x02, A2, gamma2) + one_Lor(x, x03, A3, gamma3)+ (py-e-d*px)/px/px*x**2 + d*x + e\n",
    "    return a\n",
    "\n",
    "\n",
    "# include phase mixing into the fit funciton\n",
    "def one_Lor_w_phase (B, B0, A, gamma, mixing_angle):\n",
    "    signal = one_Lorentzian(B, B0, A, gamma) + np.sin(mixing_angle*np.pi/180) * (A * (B-B0) / ( (B-B0)**2 + gamma**2 ))\n",
    "    return signal / np.sqrt( 1 + (np.sin(mixing_angle*np.pi/180))**2 )\n",
    "\n",
    "def one_Lor_w_phase_and_offset (B, B0, A, gamma, mixing_angle, offset):\n",
    "    signal = one_Lorentzian(B, B0, A, gamma) + np.sin(mixing_angle*np.pi/180) * (A * (B-B0) / ( (B-B0)**2 + gamma**2 ))\n",
    "    return signal / np.sqrt( 1 + (np.sin(mixing_angle*np.pi/180))**2 ) + offset\n",
    "\n",
    "def one_Lor_derivative_w_phase (B, B0, A, gamma, mixing_angle):\n",
    "    #amp_derivative = one_Lor(B, B0, A, gamma) \n",
    "    #phase_derivative = A * ( 1 / ( (B-B0)**2 + gamma**2 ) - 2*(B-B0)**2 / ( (B-B0)**2 + gamma**2 )**2 )\n",
    "    #signal = amp_derivative + np.sin(mixing_angle*np.pi/180) * phase_derivative\n",
    "    signal = -np.gradient(one_Lor_w_phase (B, B0, A, gamma, mixing_angle), B)\n",
    "    return signal\n",
    "\n",
    "def one_Lor_derivative_w_phase_quadr_b (B, B0, A, gamma, mixing_angle, c, d, e):\n",
    "    signal = one_Lor_derivative_w_phase (B, B0, A, gamma, mixing_angle) + c*B**2 + d*B + e\n",
    "    return signal\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def g_factor (frequency,B_resonance):\n",
    "    g = frequency*10000/B_resonance[:,0]/13.98\n",
    "    g_err = B_resonance[:,1]*frequency*10000/B_resonance[:,0]/B_resonance[:,0]/13.98\n",
    "    return g, g_err\n",
    "\n",
    "def g_eff (frequency,Bres, Berr):\n",
    "    g = frequency*10000/Bres/13.98\n",
    "    g_err = Berr*frequency*10000/Bres/Bres/13.98\n",
    "    return g, g_err\n",
    "\n",
    "# switch to elements i, j of a list\n",
    "def switch (array, i, j):\n",
    "    a = array[i]\n",
    "    b = array[j]\n",
    "    array[i] = b\n",
    "    array[j] = a\n",
    "    return array\n",
    "\n",
    "\n",
    "# in the Li case\n",
    "# change of attenuation at T[13]-T[14] and T[34]-T[35]\n",
    "def rescale_A_Li (A, dA):\n",
    "    A_switch = A #switch(A, 34, 35)\n",
    "    Aerr_switch = dA #switch(dA, 34, 35)\n",
    "        \n",
    "    A_new = np.zeros(len(A))\n",
    "    \n",
    "    A_new[:14] = A_switch[:14]\n",
    "    A_new[14:35] = A_switch[14:35] * A_switch[13] / A_switch[14]\n",
    "    A_new[35:] = A_switch[35:] * A_switch[13] / A_switch[14] * A_switch[34] / A_switch[35]\n",
    "    \n",
    "    Aerr_new = np.zeros(len(dA))\n",
    "    Aerr_new[:14] = Aerr_switch[:14]\n",
    "    Aerr_new[14:35] = Aerr_switch[14:35] * A_switch[13] / A_switch[14]\n",
    "    Aerr_new[35:] = Aerr_switch[35:] * A_switch[13] / A_switch[14] * A_switch[34] / A_switch[35]\n",
    "    \n",
    "    #A_new[35:] = A_switch[35:]\n",
    "    #A_new[14:35] = A_switch[14:35] * A_switch[35] / A_switch[34]\n",
    "    #A_new[:14] = A_switch[:14] * A_switch[14] / A_switch[13] * A_switch[35] / A_switch[34]\n",
    "    \n",
    "    #Aerr_new = np.zeros(len(dA))\n",
    "    #Aerr_new[35:] = Aerr_switch[35:]\n",
    "    #Aerr_new[14:35] = Aerr_switch[14:35] * A_switch[35] / A_switch[34]\n",
    "    #Aerr_new[:14] = Aerr_switch[:14] * A_switch[14] / A_switch[13] * A_switch[35] / A_switch[34]\n",
    "\n",
    "    \n",
    "    return A_new, Aerr_new\n",
    "\n",
    "\n",
    "# in the Na case\n",
    "# change of attenuation at T[12]-T[13]\n",
    "def rescale_A_Na (A, dA):\n",
    "    A_new = np.zeros(len(A))\n",
    "    \n",
    "#    A_new[:13] = A[:13,0] \n",
    "#    A_new[13:] = A[13:,0] * A[12,0]/A[13,0]   \n",
    "    \n",
    "    A_new[:13] = A[:13] * A[13]/A[12]\n",
    "    A_new[13:] = A[13:]    \n",
    "    \n",
    "    Aerr_new = np.zeros(len(A))\n",
    "    Aerr_new[:13] = dA[:13] * A[13]/A[12]\n",
    "    Aerr_new[13:] = dA[13:] \n",
    "    \n",
    "    \n",
    "    #A_new[:13] = A[:13]\n",
    "    #A_new[13:] = A[13:] * A[12]/A[13]\n",
    "    \n",
    "    #Aerr_new[:13] = dA[:13] \n",
    "    #Aerr_new[13:] = dA[13:] * A[12]/A[13]\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    return A_new, Aerr_new\n",
    "\n",
    "\n",
    "def rescale_A (A, dA, compound):\n",
    "    if compound == 'Li':\n",
    "        out = rescale_A_Li(A, dA)\n",
    "    elif compound == 'Na':\n",
    "        out = rescale_A_Na(A, dA)\n",
    "    else:\n",
    "        raise Exception('The only two possible input arguments for \"compound\" are \"Li\" or \"Na\"')\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot several ESR-data sets with the fit curves\n",
    "## this is a general plot function allowing for various final plots\n",
    "## but only for fits with several Lorentzians"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# temp can either be a single number or a list of numbers\n",
    "# compound can be 'Li' or 'Na' (has to be a string!)\n",
    "# ncolumns gives the number of columns if there should be several different temperatures\n",
    "# grid: 'yes' if you want to show grid lines, anything else if you don't\n",
    "# raw: 'yes' if you want to show the actual raw data (even without background subtracted); anything else if you don't\n",
    "# additional_folder: if the individual_fit_curves files are not directly in \"...\\\\individual_fit_curves\" here you\n",
    "# have to enter the additional folder name (if they are directly here enter 'no')\n",
    "# one_Lor: do you also want to show the fit of one Lorentzian: 'yes' or 'no'\n",
    "def plot_fits (temp, compound, ncolumns, grid, raw, additional_folder, one_Lor):\n",
    "    \n",
    "    \n",
    "    folder_general = \"C:\\\\Users\\\\F25_1.307_b\\\\Box Sync\\\\Klingeler_Masterarbeit\\\\howardevansite\\\\\"\n",
    "    \n",
    "    if compound == 'Li':\n",
    "        folder_specific = 'LiCuFe2(VO4)3 powder\\\\X-band\\\\21_02_2019'\n",
    "    \n",
    "    elif compound == 'Na':\n",
    "        folder_specific = 'NaCuFe2(VO4)3 powder\\\\X-band\\\\19_02_2019'\n",
    "        \n",
    "    else:\n",
    "        raise Exception('The variable \"compound\" can only take Li or Na (and they have to be strings!). You entered: {}'.format(compound))\n",
    "        \n",
    "\n",
    "    # list of the names of all the files in \"folder\" \n",
    "    if additional_folder == 'no':\n",
    "        folder1 = folder_general + folder_specific + '\\\\individual_fit_curves'\n",
    "    else:\n",
    "        folder1 = folder_general + folder_specific + '\\\\individual_fit_curves\\\\' + additional_folder\n",
    "    files = [i for i in os.listdir(folder1)]\n",
    "    files = np.array(os.listdir(folder1))\n",
    "    files = files[ [i.find('individual')!=-1 for i in files] ]\n",
    "    \n",
    "    # write function that finds the temperature in the file names\n",
    "    def find_T (filename):\n",
    "        lower = filename.find('s')\n",
    "        upper = filename.find('K')\n",
    "        T = filename[lower+2:upper-1]\n",
    "        return float(T)\n",
    "    \n",
    "    \n",
    "    # create an array of temperatures of the filenames\n",
    "    file_T = np.array([find_T(i) for i in files])\n",
    "    \n",
    "    \n",
    "###################### gives an array of all the temperature that are the closest to  the given temperature\n",
    "    # only gives more than one entry if several temperatures have the same distance from the given one\n",
    "    if type(temp)==float or type(temp)==int or len(temp)==1:\n",
    "        possible_temperatures = file_T[abs(file_T-temp) - min(abs(file_T-temp)) < 0.01]\n",
    "    \n",
    "    elif type(temp) == list:\n",
    "        mask_lower = file_T >= temp[0]\n",
    "        mask_upper = file_T <= temp[1]\n",
    "        mask = [ np.all([mask_lower[i], mask_upper[i]]) for i in np.arange(len(mask_upper)) ]\n",
    "        possible_temperatures = file_T[mask]\n",
    "    \n",
    "    else:\n",
    "        raise Exception('The temperature you entered does not have the right type. Only enter a single value or a list of integers or floats.')\n",
    "        \n",
    "        \n",
    "    if len(possible_temperatures) == 0:\n",
    "        raise Exception('There is no measured data file in the chosen temperature range. Choose a wider range.')\n",
    "        \n",
    "           \n",
    "        \n",
    "    \n",
    "    \n",
    "###################### create array of filenames of data taken at the temperatures in 'possible_temperatures'\n",
    "    # get the files with the temperatures from possible_temperatures\n",
    "    mask = []\n",
    "    for t in possible_temperatures:\n",
    "        mask.append( abs(file_T-t) < 0.01 )\n",
    "    mask = np.array(mask)\n",
    "    \n",
    "    final_mask = []\n",
    "    for i in np.arange(len(file_T)):\n",
    "        final_mask.append(np.any(np.transpose(mask)[i]))\n",
    "    \n",
    "    files = files[final_mask]\n",
    "    \n",
    "    # since you're already at it also import the right filename from fits of only one Lorentzian\n",
    "    if one_Lor == 'yes':\n",
    "        folder = folder_general + folder_specific + '\\\\individual_fit_curves'\n",
    "        files0 = np.array(os.listdir(folder+'\\\\single_Lorentzian'))\n",
    "        files0 = files0[final_mask]\n",
    "    \n",
    "#######################################################################################\n",
    "#######################################################################################\n",
    "# plot stuff\n",
    "    \n",
    "    files_T = [find_T(i) for i in files]\n",
    "    files = files[np.argsort(files_T)]\n",
    "    files_T = sorted(files_T)\n",
    "    \n",
    "    if len(files) < ncolumns:\n",
    "        ncolumns = len(files)\n",
    "    else:\n",
    "        ncolumns = ncolumns\n",
    "    nrows = math.ceil( len(files) / ncolumns )\n",
    "    \n",
    "    \n",
    "    fig, axes = plt.subplots( nrows, ncolumns, sharex=True, sharey=True, figsize=(15*ncolumns,10*nrows) )\n",
    "    \n",
    "    if nrows > 1:\n",
    "        \n",
    "        for i in np.arange(len(files)+1)[1:]:\n",
    "            \n",
    "            d = data_import(folder1 +'\\\\'+files[i-1], 3)\n",
    "                        \n",
    "            if len(d) < 8:\n",
    "                axes[math.ceil(i/ncolumns)-1, (i-1)%ncolumns].plot(d[0], d[2])\n",
    "                axes[math.ceil(i/ncolumns)-1, (i-1)%ncolumns].plot(d[0], d[3])\n",
    "                axes[math.ceil(i/ncolumns)-1, (i-1)%ncolumns].plot(d[0], d[4])\n",
    "                axes[math.ceil(i/ncolumns)-1, (i-1)%ncolumns].plot(d[0], d[6])\n",
    "                axes[math.ceil(i/ncolumns)-1, (i-1)%ncolumns].scatter(d[0], d[1], s=5, c = 'gray')\n",
    "                if raw == 'yes':\n",
    "                    axes[math.ceil(i/ncolumns)-1, (i-1)%ncolumns].scatter(d[0], d[1]+d[6], s=1, c = 'pink')\n",
    "                if one_Lor == 'yes':\n",
    "                    d0 = data_import(folder +'\\\\single_Lorentzian\\\\'+files0[i-1], 3)\n",
    "                    axes[math.ceil(i/ncolumns)-1, (i-1)%ncolumns].plot(d0[0], d0[2])\n",
    "                \n",
    "                axes[math.ceil(i/ncolumns)-1, (i-1)%ncolumns].legend(['sum', 'L1', 'L2', 'background',\n",
    "                                                                     'data minus background', 'raw data'], fontsize = 20)\n",
    "            \n",
    "            else:\n",
    "                axes[math.ceil(i/ncolumns)-1, (i-1)%ncolumns].plot(d[0], d[2])\n",
    "                axes[math.ceil(i/ncolumns)-1, (i-1)%ncolumns].plot(d[0], d[3])\n",
    "                axes[math.ceil(i/ncolumns)-1, (i-1)%ncolumns].plot(d[0], d[4])\n",
    "                axes[math.ceil(i/ncolumns)-1, (i-1)%ncolumns].plot(d[0], d[5])\n",
    "                axes[math.ceil(i/ncolumns)-1, (i-1)%ncolumns].plot(d[0], d[7])\n",
    "                axes[math.ceil(i/ncolumns)-1, (i-1)%ncolumns].scatter(d[0], d[1], s=5, c = 'gray')\n",
    "                if raw == 'yes':\n",
    "                    axes[math.ceil(i/ncolumns)-1, (i-1)%ncolumns].scatter(d[0], d[1]+d[7], s=1, c = 'pink')\n",
    "                if one_Lor == 'yes':\n",
    "                    axes[math.ceil(i/ncolumns)-1, (i-1)%ncolumns].plot(d0[0], d0[2])\n",
    "                    \n",
    "                axes[math.ceil(i/ncolumns)-1, (i-1)%ncolumns].legend(['sum', 'L1', 'L2', 'L3', 'background',\n",
    "                                                                     'data minus background', 'raw data'], fontsize = 20)\n",
    "            \n",
    "            #axes[math.ceil(i/ncolumns)-1, (i-1)%ncolumns].text(0.6,15, str(files_T[i-1])+ ' K', color='black', fontsize=30)\n",
    "            axes[math.ceil(i/ncolumns)-1, (i-1)%ncolumns].set_title(str(files_T[i-1])+' K', fontsize = 30)\n",
    "            if grid == 'yes':\n",
    "                axes.grid(color='gray', linestyle='--', linewidth=1)\n",
    "           \n",
    "        \n",
    "    elif ncolumns > 1:\n",
    "        \n",
    "        for i in np.arange(len(files)+1)[1:]:\n",
    "            \n",
    "            d = data_import(folder1 +'\\\\'+files[i-1], 3)\n",
    "                        \n",
    "            if len(d) < 8:\n",
    "                axes[i-1].scatter(d[0], d[1], s=5, c = 'gray')\n",
    "                axes[i-1].plot(d[0], d[2])\n",
    "                axes[i-1].plot(d[0], d[3])\n",
    "                axes[i-1].plot(d[0], d[4])\n",
    "                axes[i-1].plot(d[0], d[6])\n",
    "                axes[i-1].scatter(d[0], d[1], s=5, c = 'gray')\n",
    "                if raw == 'yes':\n",
    "                    axes[i-1].scatter(d[0], d[1]+d[6], s=1, c = 'pink')\n",
    "                if one_Lor == 'yes':\n",
    "                    d0 = data_import(folder +'\\\\single_Lorentzian\\\\'+files0[i-1], 3)\n",
    "                    axes[i-1].plot(d0[0], d0[2])\n",
    "                axes[i-1].legend(['sum', 'L1', 'L2', 'background', 'data minus background', 'raw data'], fontsize = 20)\n",
    "                \n",
    "            else:\n",
    "                axes[i-1].plot(d[0], d[2])\n",
    "                axes[i-1].plot(d[0], d[3])\n",
    "                axes[i-1].plot(d[0], d[4])\n",
    "                axes[i-1].plot(d[0], d[5])\n",
    "                axes[i-1].plot(d[0], d[7])\n",
    "                axes[i-1].scatter(d[0], d[1], s=5, c = 'gray')\n",
    "                if raw == 'yes':\n",
    "                    axes[i-1].scatter(d[0], d[1]+d[7], s=1, c = 'pink')\n",
    "                if one_Lor == 'yes':\n",
    "                    axes[i-1].plot(d0[0], d0[2])\n",
    "                axes[i-1].legend(['sum', 'L1', 'L2', 'L3', 'background', 'data minus background', 'raw data'], fontsize = 20)\n",
    "            \n",
    "            #axes[math.ceil(i/ncolumns)-1, (i-1)%ncolumns].text(0.6,15, str(files_T[i-1])+ ' K', color='black', fontsize=30)\n",
    "            axes[i-1].set_title(str(files_T[i-1])+' K', fontsize = 30)\n",
    "            if grid == 'yes':\n",
    "                axes.grid(color='gray', linestyle='--', linewidth=1)\n",
    "            \n",
    "            \n",
    "    else:\n",
    "        \n",
    "        for i in np.arange(len(files)+1)[1:]:\n",
    "            \n",
    "            d = data_import(folder1 +'\\\\'+files[i-1], 3)\n",
    "                        \n",
    "            if len(d) < 8:\n",
    "                axes.plot(d[0], d[2])\n",
    "                axes.plot(d[0], d[3])\n",
    "                axes.plot(d[0], d[4])\n",
    "                axes.plot(d[0], d[6])\n",
    "                axes.scatter(d[0], d[1], s=5, c = 'gray')\n",
    "                if raw == 'yes':\n",
    "                    axes.scatter(d[0], d[1]+d[6], s=1, c = 'pink')\n",
    "                if one_Lor == 'yes':\n",
    "                    d0 = data_import(folder +'\\\\single_Lorentzian\\\\'+files0[i-1], 3)\n",
    "                    axes.plot(d0[0], d0[2])\n",
    "                axes.legend(['sum', 'L1', 'L2', 'background', 'data minus background', 'raw data'], fontsize = 20)\n",
    "                                \n",
    "                \n",
    "            else:\n",
    "                axes.plot(d[0], d[2])\n",
    "                axes.plot(d[0], d[3])\n",
    "                axes.plot(d[0], d[4])\n",
    "                axes.plot(d[0], d[5])\n",
    "                axes.plot(d[0], d[7])\n",
    "                axes.scatter(d[0], d[1], s=5, c = 'gray')\n",
    "                if raw == 'yes':\n",
    "                    axes.scatter(d[0], d[1]+d[7], s=1, c = 'pink')\n",
    "                if one_Lor == 'yes':\n",
    "                    axes.plot(d0[0], d0[2])\n",
    "                axes.legend(['sum', 'L1', 'L2', 'L3', 'background', 'data minus background', 'raw data'], fontsize = 20)\n",
    "                \n",
    "            #axes[math.ceil(i/ncolumns)-1, (i-1)%ncolumns].text(0.6,15, str(files_T[i-1])+ ' K', color='black', fontsize=30)\n",
    "            axes.set_title(str(files_T[i-1])+' K', fontsize = 30)\n",
    "            if grid == 'yes':\n",
    "                axes.grid(color='gray', linestyle='--', linewidth=1)\n",
    "            \n",
    "    \n",
    "    plt.subplots_adjust(wspace=0.01, hspace=0.3)\n",
    "    \n",
    "    b=0\n",
    "    for i in np.arange(nrows):\n",
    "        for j in np.arange(ncolumns):\n",
    "            if b > len(files)-1:\n",
    "                axes[i,j].axis('off')\n",
    "                b=b+1\n",
    "            else:\n",
    "                b=b+1\n",
    "    \n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
